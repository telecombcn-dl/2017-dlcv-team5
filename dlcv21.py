from __future__ import print_function
import keras
from keras.models import load_model
from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img
from keras.models import Sequential, Model
from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D
from keras.utils import plot_model
import os
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt



batch_size = 20
num_classes = 13
epochs = 100
data_augmentation = False
dir = "/imatge/mcata/Terrassa/"
type=''

img_width, img_height = 32,32

# Load dict images
def load_image(dir, type):
    full_dir = dir + type + 'images/'
    dict_images = {}
    for filename in os.listdir(full_dir):
        name = os.path.splitext(filename)[0]
        img = load_img(full_dir + filename, target_size=(img_width, img_height))
        dict_images[name] = img_to_array(img, data_format='channels_last')

    return dict_images

# Load dict labels
def load_labels(dir, type):
    dict_labels = {}
    classes = set([])
    full_dir = dir + type
    with open(full_dir + 'annotation.txt', 'r') as f:
        next(f)
        for l in f:
            x, y = l.split()
            dict_labels[x] = y
            classes.add(y)

    return classes, dict_labels

def create_db(dict_img, dict_labels, classes):
    x_train = []
    labels = []
    for key, value in dict_img.iteritems():
        x_train.append(value)
        name = dict_labels[key]
        idx = classes.index(name)
        labels.append(idx)

    x_train = np.asarray(x_train)
    y_train = np.asarray(labels)

    return x_train, y_train




dict_img = load_image(dir, 'train/')
print("# train samples:", len(dict_img))

classes, dict_labels = load_labels(dir, 'train/')
classes = list(classes)
print('Classes:', classes)
print("# train labels:", len(dict_labels))

x_train, y_train = create_db(dict_img, dict_labels, classes)
print('x_train shape:', x_train.shape)
print('y_train shape:', y_train.shape)

dict_img = load_image(dir, 'val/')
print("# val samples:", len(dict_img))

classes, dict_labels = load_labels(dir, 'val/')
classes = list(classes)
print('Classes:', classes)
print("# val labels:", len(dict_labels))
num_classes = len(classes)
x_val, y_val = create_db(dict_img, dict_labels, classes)
print('x_val shape:', x_val.shape)
print('y_val shape:', y_val.shape)


# The data, shuffled and split between train and test sets:

#print('x_train shape:', x_train.shape)
#print(x_train.shape[0], 'train samples')
#print(x_test.shape[0], 'test samples')
# Convert class vectors to binary class matrices.
y_train = keras.utils.to_categorical(y_train, num_classes)
y_val = keras.utils.to_categorical(y_val, num_classes)

model = load_model('/imatge/mcata/Terrassa/modelo.h5')

model.layers.pop()
model.outputs = [model.layers[-1].output]
model.layers[-1].outbound_nodes = []
model.add(Dense(13, activation='softmax'))
print(len(model.layers))

for layer in model.layers[:20]:
   layer.trainable = False
# initiate RMSprop optimizer
opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)

# Let's train the model using RMSprop
model.compile(loss='categorical_crossentropy',
              optimizer=opt,
              metrics=['accuracy'])
print (model.input_shape)
print(model.output_shape)
print ('aquesta es la output shape')
x_train = x_train.astype('float32')
x_val = x_val.astype('float32')
x_train /= 255
x_val /= 255

if not data_augmentation:
    print('Not using data augmentation.')
    history = model.fit(x_train, y_train,
              batch_size=batch_size,
              epochs=epochs,
              validation_data=(x_val, y_val))
              #shuffle=True)
else:
    print('Using real-time data augmentation.')
    # This will do preprocessing and realtime data augmentation:
    datagen = ImageDataGenerator(
        featurewise_center=False,  # set input mean to 0 over the dataset
        samplewise_center=False,  # set each sample mean to 0
        featurewise_std_normalization=False,  # divide inputs by std of the dataset
        samplewise_std_normalization=False,  # divide each input by its std
        zca_whitening=False,  # apply ZCA whitening
        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)
        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)
        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)
        horizontal_flip=True,  # randomly flip images
        vertical_flip=False)  # randomly flip images

    # Compute quantities required for feature-wise normalization
    # (std, mean, and principal components if ZCA whitening is applied).
    datagen.fit(x_train)

    # Fit the model on the batches generated by datagen.flow().
    history = model.fit_generator(datagen.flow(x_train, y_train,
                                     batch_size=batch_size),
                        steps_per_epoch=x_train.shape[0] // batch_size,
                        epochs=epochs,
                        validation_data=(x_val, y_val))

    plot_model(model, to_file='model.png')

print(history.history.keys())
fig, axis = plt.subplots(1,2)#,figsize=(15,5))

# summarize history for accuracy

axis[0].plot(history.history['acc'])
axis[0].plot(history.history['val_acc'])
axis[0].set_title('model accuracy')
axis[0].set_ylabel('accuracy')
axis[0].set_xlabel('epoch')
axis[0].legend(['train', 'test'], loc='upper left')
#plt.show()
#axis axis[0].savefig('/imatge/mcata/Terrassa/accuracy_22.png')
# summarize history for loss

axis[1].plot(history.history['loss'])
axis[1].plot(history.history['val_loss'])
axis[1].set_title('model loss')
axis[1].set_ylabel('loss')
axis[1].set_xlabel('epoch')
axis[1].legend(['train', 'test'], loc='upper left')
#plt.show()
plt.savefig('/imatge/mcata/Terrassa/task_21.png')
